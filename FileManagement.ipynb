{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mughilan16/big-data-lab/blob/master/FileManagement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yskbDhVYRtWp"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk\n",
        "!wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n",
        "!tar fx hadoop-3.3.6.tar.gz\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/content/hadoop-3.3.6\"\n",
        "!ln -s /content/hadoop-3.3.6/bin/* /usr/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List all files in a folder"
      ],
      "metadata": {
        "id": "J5WEsGDmSQvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -ls data"
      ],
      "metadata": {
        "id": "WKY4PAEwSBvD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a new folder"
      ],
      "metadata": {
        "id": "iId8oUofSVKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -mkdir data"
      ],
      "metadata": {
        "id": "KrUb4vpSSXG8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a new file"
      ],
      "metadata": {
        "id": "qQGrPJtMSfgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -touch data/file.txt"
      ],
      "metadata": {
        "id": "hunxONs8Se0b"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/file.txt\", \"w\") as f:\n",
        "    f.write(\"Hello\")"
      ],
      "metadata": {
        "id": "E3xzzXl-MhO8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display File"
      ],
      "metadata": {
        "id": "QJrbqA9uUiJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -cat data/file.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POO3BX32UkK8",
        "outputId": "fe8f1c7f-6278-44ab-a388-89f9bb00da92"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-12 05:49:10,381 INFO fs.FSInputChecker: Found checksum error: b[0, 0]=\n",
            "org.apache.hadoop.fs.ChecksumException: Checksum error: file:/content/data/file.txt at 0\n",
            "\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.readChunk(ChecksumFileSystem.java:303)\n",
            "\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:305)\n",
            "\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:257)\n",
            "\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:202)\n",
            "\tat java.io.DataInputStream.read(DataInputStream.java:100)\n",
            "\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)\n",
            "\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:69)\n",
            "\tat org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:133)\n",
            "\tat org.apache.hadoop.fs.shell.Display$Cat.printToStdout(Display.java:101)\n",
            "\tat org.apache.hadoop.fs.shell.Display$Cat.processPath(Display.java:96)\n",
            "\tat org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:382)\n",
            "\tat org.apache.hadoop.fs.shell.Command.processPaths(Command.java:345)\n",
            "\tat org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:318)\n",
            "\tat org.apache.hadoop.fs.shell.Command.processArgument(Command.java:300)\n",
            "\tat org.apache.hadoop.fs.shell.Command.processArguments(Command.java:284)\n",
            "\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121)\n",
            "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:191)\n",
            "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:327)\n",
            "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82)\n",
            "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:97)\n",
            "\tat org.apache.hadoop.fs.FsShell.main(FsShell.java:390)\n",
            "cat: Checksum error: file:/content/data/file.txt at 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move file"
      ],
      "metadata": {
        "id": "MygQor68SoAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -mv data/file.txt file.txt"
      ],
      "metadata": {
        "id": "EYZLB1hNStjS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy a file"
      ],
      "metadata": {
        "id": "Pc7dRV4cYbcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -cp file1.txt example/file.txt"
      ],
      "metadata": {
        "id": "gFT8MA3AYeKF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove a file"
      ],
      "metadata": {
        "id": "jJL74RjyYu4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -rm data/file.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzwknA_bYtnW",
        "outputId": "7577f43b-8285-4e3d-d6d4-5584e1386a12"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-12 06:19:09,802 INFO Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
            "Deleted data/file.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove a folder"
      ],
      "metadata": {
        "id": "TiTgy8UEY7Ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -rmdir data"
      ],
      "metadata": {
        "id": "RpQ2Gl8TY4ZV"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}